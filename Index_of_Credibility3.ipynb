{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10607299,"sourceType":"datasetVersion","datasetId":6566330}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ndata_dir = \"/kaggle/input/fake-news-politics\"  # Правильный путь к данным\n\ntrain_path = os.path.join(data_dir, \"train.tsv\")\nvalid_path = os.path.join(data_dir, \"valid.tsv\")\ntest_path = os.path.join(data_dir, \"test.tsv\")\nprint(os.path.exists(train_path))  # Должно вывести True\nprint(os.path.exists(valid_path))  \nprint(os.path.exists(test_path))\nprint(train_path)\nprint(valid_path)\nprint(test_path)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:25:05.661563Z","iopub.execute_input":"2025-02-01T07:25:05.661889Z","iopub.status.idle":"2025-02-01T07:25:06.015520Z","shell.execute_reply.started":"2025-02-01T07:25:05.661867Z","shell.execute_reply":"2025-02-01T07:25:06.014738Z"}},"outputs":[{"name":"stdout","text":"True\nTrue\nTrue\n/kaggle/input/fake-news-politics/train.tsv\n/kaggle/input/fake-news-politics/valid.tsv\n/kaggle/input/fake-news-politics/test.tsv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\nwith open(train_path, \"r\", encoding=\"utf-8\") as f:\n    for _ in range(5):  # Первые 5 строк\n        print(f.readline())\ncolumns = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job\", \"state\", \"party affiliation\", \"credit history\"]  # Укажите все столбцы\ndf_train = pd.read_csv(train_path, sep=\"\\t\", encoding=\"utf-8\")\ndf_valid = pd.read_csv(valid_path, sep=\"\\t\", encoding=\"utf-8\")\ndf_test = pd.read_csv(test_path, sep=\"\\t\", encoding=\"utf-8\")\n# Выводим первые строки\nprint(df_train.head())\nprint(df_valid.head())\nprint(df_test.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:25:10.769684Z","iopub.execute_input":"2025-02-01T07:25:10.770111Z","iopub.status.idle":"2025-02-01T07:25:10.898427Z","shell.execute_reply.started":"2025-02-01T07:25:10.770086Z","shell.execute_reply":"2025-02-01T07:25:10.897395Z"}},"outputs":[{"name":"stdout","text":"2635.json\tfalse\tSays the Annies List political group supports third-trimester abortions on demand.\tabortion\tdwayne-bohac\tState representative\tTexas\trepublican\t0\t1\t0\t0\t0\ta mailer\n\n10540.json\thalf-true\tWhen did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.\tenergy,history,job-accomplishments\tscott-surovell\tState delegate\tVirginia\tdemocrat\t0\t0\t1\t1\t0\ta floor speech.\n\n324.json\tmostly-true\tHillary Clinton agrees with John McCain \"by voting to give George Bush the benefit of the doubt on Iran.\"\tforeign-policy\tbarack-obama\tPresident\tIllinois\tdemocrat\t70\t71\t160\t163\t9\tDenver\n\n1123.json\tfalse\tHealth care reform legislation is likely to mandate free sex change surgeries.\thealth-care\tblog-posting\t\t\tnone\t7\t19\t3\t5\t44\ta news release\n\n9028.json\thalf-true\tThe economic turnaround started at the end of my term.\teconomy,jobs\tcharlie-crist\t\tFlorida\tdemocrat\t15\t9\t20\t19\t2\tan interview on CNN\n\n    2635.json        false  \\\n0  10540.json    half-true   \n1    324.json  mostly-true   \n2   1123.json        false   \n3   9028.json    half-true   \n4  12465.json         true   \n\n  Says the Annies List political group supports third-trimester abortions on demand.  \\\n0  When did the decline of coal start? It started...                                   \n1  Hillary Clinton agrees with John McCain \"by vo...                                   \n2  Health care reform legislation is likely to ma...                                   \n3  The economic turnaround started at the end of ...                                   \n4  The Chicago Bears have had more starting quart...                                   \n\n                             abortion    dwayne-bohac  \\\n0  energy,history,job-accomplishments  scott-surovell   \n1                      foreign-policy    barack-obama   \n2                         health-care    blog-posting   \n3                        economy,jobs   charlie-crist   \n4                           education       robin-vos   \n\n         State representative      Texas  republican     0     1    0.1  \\\n0              State delegate   Virginia    democrat   0.0   0.0    1.0   \n1                   President   Illinois    democrat  70.0  71.0  160.0   \n2                         NaN        NaN        none   7.0  19.0    3.0   \n3                         NaN    Florida    democrat  15.0   9.0   20.0   \n4  Wisconsin Assembly speaker  Wisconsin  republican   0.0   3.0    2.0   \n\n     0.2   0.3                   a mailer  \n0    1.0   0.0            a floor speech.  \n1  163.0   9.0                     Denver  \n2    5.0  44.0             a news release  \n3   19.0   2.0        an interview on CNN  \n4    5.0   1.0  a an online opinion-piece  \n  12134.json barely-true We have less Americans working now than in the 70s.  \\\n0   238.json  pants-fire  When Obama was sworn into office, he DID NOT u...    \n1  7891.json       false  Says Having organizations parading as being so...    \n2  8169.json   half-true     Says nearly half of Oregons children are poor.    \n3   929.json   half-true  On attacks by Republicans that various program...    \n4  9416.json       false  Says when armed civilians stop mass shootings ...    \n\n                       economy,jobs   vicky-hartzler  \\\n0  obama-birth-certificate,religion      chain-email   \n1   campaign-finance,congress,taxes  earl-blumenauer   \n2                           poverty  jim-francesconi   \n3                  economy,stimulus     barack-obama   \n4                              guns       jim-rubens   \n\n                             U.S. Representative       Missouri  republican  \\\n0                                            NaN            NaN        none   \n1                            U.S. representative         Oregon    democrat   \n2  Member of the State Board of Higher Education         Oregon        none   \n3                                      President       Illinois    democrat   \n4                           Small business owner  New Hampshire  republican   \n\n    1   0  1.1  0.1  0.2                 an interview with ABC17 News  \n0  11  43    8    5  105                                          NaN  \n1   0   1    1    1    0                a U.S. Ways and Means hearing  \n2   0   1    1    1    0                           an opinion article  \n3  70  71  160  163    9                      interview with CBS News  \n4   1   1    0    1    0  in an interview at gun shop in Hudson, N.H.  \n   11972.json        true  \\\n0  11685.json       false   \n1  11096.json       false   \n2   5209.json   half-true   \n3   9524.json  pants-fire   \n4   5962.json        true   \n\n  Building a wall on the U.S.-Mexico border will take literally years.  \\\n0  Wisconsin is on pace to double the number of l...                     \n1  Says John McCain has done nothing to help the ...                     \n2  Suzanne Bonamici supports a plan that will cut...                     \n3  When asked by a reporter whether hes at the ce...                     \n4  Over the past five years the federal governmen...                     \n\n                                         immigration  \\\n0                                               jobs   \n1                    military,veterans,voting-record   \n2  medicare,message-machine-2012,campaign-adverti...   \n3  campaign-finance,legal-issues,campaign-adverti...   \n4                 federal-budget,pensions,retirement   \n\n                         rick-perry              Governor         Texas  \\\n0                 katrina-shankland  State representative     Wisconsin   \n1                      donald-trump       President-Elect      New York   \n2                     rob-cornilles            consultant        Oregon   \n3  state-democratic-party-wisconsin                   NaN     Wisconsin   \n4                   brendan-doherty                   NaN  Rhode Island   \n\n   republican  30  30.1  42  23  18               Radio interview  \n0    democrat   2     1   0   0   0             a news conference  \n1  republican  63   114  51  37  61  comments on ABC's This Week.  \n2  republican   1     1   3   1   1                  a radio show  \n3    democrat   5     7   2   2   7                   a web video  \n4  republican   1     2   1   1   0            a campaign website  \n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df_train = pd.read_csv(train_path, sep=\"\\t\", encoding=\"utf-8\")\nprint(\"Columns in dataset:\", df_train.columns)\n# Переименовываем столбцы для удобства\ndf_train = df_train.rename(columns={\"Says the Annies List political group supports third-trimester abortions on demand.\": \"statement\", \"false\": \"label\"})\ndf_valid = df_valid.rename(columns={\"We have less Americans working now than in the 70s.\": \"statement\", \"barely-true\": \"label\"})\ndf_test = df_test.rename(columns={\"Building a wall on the U.S.-Mexico border will take literally years.\": \"statement\", \"true\": \"label\"})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:27:18.813669Z","iopub.execute_input":"2025-02-01T07:27:18.813946Z","iopub.status.idle":"2025-02-01T07:27:18.864698Z","shell.execute_reply.started":"2025-02-01T07:27:18.813925Z","shell.execute_reply":"2025-02-01T07:27:18.864013Z"}},"outputs":[{"name":"stdout","text":"Columns in dataset: Index(['2635.json', 'false',\n       'Says the Annies List political group supports third-trimester abortions on demand.',\n       'abortion', 'dwayne-bohac', 'State representative', 'Texas',\n       'republican', '0', '1', '0.1', '0.2', '0.3', 'a mailer'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\n\n# Определяем названия столбцов\ncolumns = [\n    \"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job\", \"state\",\n    \"party affiliation\", \"credit history\", \"barely_true_count\",\n    \"false_count\", \"half_true_count\", \"mostly_true_count\", \"context\"\n]\n\nimport os\ndata_dir = \"/kaggle/input/fake-news-politics\"  # Правильный путь к данным\n\ntrain_path = os.path.join(data_dir, \"train.tsv\")\nvalid_path = os.path.join(data_dir, \"valid.tsv\")\ntest_path = os.path.join(data_dir, \"test.tsv\")\nprint(os.path.exists(train_path))  # Должно вывести True\nprint(os.path.exists(valid_path))  \nprint(os.path.exists(test_path))\nprint(train_path)\nprint(valid_path)\nprint(test_path)\n\n# Загружаем данные без заголовков\ndf_train = pd.read_csv(train_path, sep=\"\\t\", encoding=\"utf-8\", header=None, names=columns)\ndf_valid = pd.read_csv(valid_path, sep=\"\\t\", encoding=\"utf-8\", header=None, names=columns)\ndf_test = pd.read_csv(test_path, sep=\"\\t\", encoding=\"utf-8\", header=None, names=columns)\n\n# Проверяем названия столбцов\nprint(\"Train dataset columns:\", df_train.columns)\n\n# Выводим первые строки для проверки\nprint(\"\\nTrain dataset head:\")\nprint(df_train.head())\n\n# Преобразуем текстовые метки в числовые\nlabel_map = {\n    \"pants-fire\": 0,\n    \"false\": 1,\n    \"barely-true\": 2,\n    \"half-true\": 3,\n    \"mostly-true\": 4,\n    \"true\": 5\n}\n\ndf_train[\"label\"] = df_train[\"label\"].map(label_map)\ndf_valid[\"label\"] = df_valid[\"label\"].map(label_map)\ndf_test[\"label\"] = df_test[\"label\"].map(label_map)\n\n# Проверяем результат\nprint(\"Train dataset labels:\", df_train[\"label\"].unique())\nprint(\"Validation dataset labels:\", df_valid[\"label\"].unique())\nprint(\"Test dataset labels:\", df_test[\"label\"].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:28:57.058598Z","iopub.execute_input":"2025-02-01T07:28:57.058930Z","iopub.status.idle":"2025-02-01T07:28:57.149821Z","shell.execute_reply.started":"2025-02-01T07:28:57.058907Z","shell.execute_reply":"2025-02-01T07:28:57.149137Z"}},"outputs":[{"name":"stdout","text":"True\nTrue\nTrue\n/kaggle/input/fake-news-politics/train.tsv\n/kaggle/input/fake-news-politics/valid.tsv\n/kaggle/input/fake-news-politics/test.tsv\nTrain dataset columns: Index(['id', 'label', 'statement', 'subject', 'speaker', 'job', 'state',\n       'party affiliation', 'credit history', 'barely_true_count',\n       'false_count', 'half_true_count', 'mostly_true_count', 'context'],\n      dtype='object')\n\nTrain dataset head:\n           id        label                                          statement  \\\n0   2635.json        false  Says the Annies List political group supports ...   \n1  10540.json    half-true  When did the decline of coal start? It started...   \n2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n3   1123.json        false  Health care reform legislation is likely to ma...   \n4   9028.json    half-true  The economic turnaround started at the end of ...   \n\n                              subject         speaker                   job  \\\n0                            abortion    dwayne-bohac  State representative   \n1  energy,history,job-accomplishments  scott-surovell        State delegate   \n2                      foreign-policy    barack-obama             President   \n3                         health-care    blog-posting                   NaN   \n4                        economy,jobs   charlie-crist                   NaN   \n\n      state party affiliation  credit history  barely_true_count  false_count  \\\n0     Texas        republican             0.0                1.0          0.0   \n1  Virginia          democrat             0.0                0.0          1.0   \n2  Illinois          democrat            70.0               71.0        160.0   \n3       NaN              none             7.0               19.0          3.0   \n4   Florida          democrat            15.0                9.0         20.0   \n\n   half_true_count  mostly_true_count              context  \n0              0.0                0.0             a mailer  \n1              1.0                0.0      a floor speech.  \n2            163.0                9.0               Denver  \n3              5.0               44.0       a news release  \n4             19.0                2.0  an interview on CNN  \nTrain dataset labels: [1 3 4 5 2 0]\nValidation dataset labels: [2 0 1 3 5 4]\nTest dataset labels: [5 1 3 0 2 4]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Убираем возможные пропуски\ndf_train.dropna(inplace=True)\ndf_valid.dropna(inplace=True)\ndf_test.dropna(inplace=True)\n\n# Смотрим на уникальные метки\nprint(df_train[\"label\"].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:29:04.473902Z","iopub.execute_input":"2025-02-01T07:29:04.474196Z","iopub.status.idle":"2025-02-01T07:29:04.498642Z","shell.execute_reply.started":"2025-02-01T07:29:04.474175Z","shell.execute_reply":"2025-02-01T07:29:04.497854Z"}},"outputs":[{"name":"stdout","text":"label\n3    1413\n4    1362\n1    1304\n5    1154\n2    1052\n0     436\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"import matplotlib.pyplot as plt\ndf_train[\"label\"].value_counts().plot(kind=\"bar\")\nplt.show()","metadata":{}},{"cell_type":"code","source":"!pip install evaluate\nimport pandas as pd\nimport re\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\nfrom datasets import Dataset\nimport evaluate\nimport numpy as np\nimport torch\nfrom sklearn.metrics import confusion_matrix\nimport wandb\n\n# Очистка текста\ndef clean_text(text):\n    text = re.sub(r\"<.*?>\", \"\", text)  # Удаление HTML-тегов\n    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  # Удаление URL\n    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Удаление специальных символов\n    text = text.lower()  # Приведение к нижнему регистру\n    return text\n\n# Определяем названия столбцов\ncolumns = [\n    \"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job\", \"state\",\n    \"party affiliation\", \"credit history\", \"barely_true_count\",\n    \"false_count\", \"half_true_count\", \"mostly_true_count\", \"context\"\n]\n\n# Загружаем данные без заголовков\ndf_train = pd.read_csv(train_path, sep=\"\\t\", encoding=\"utf-8\", header=None, names=columns)\ndf_valid = pd.read_csv(valid_path, sep=\"\\t\", encoding=\"utf-8\", header=None, names=columns)\ndf_test = pd.read_csv(test_path, sep=\"\\t\", encoding=\"utf-8\", header=None, names=columns)\n\n# Очистка текста\ndf_train[\"statement\"] = df_train[\"statement\"].apply(clean_text)\ndf_valid[\"statement\"] = df_valid[\"statement\"].apply(clean_text)\ndf_test[\"statement\"] = df_test[\"statement\"].apply(clean_text)\n\n# Преобразуем текстовые метки в числовые\nlabel_map = {\n    \"pants-fire\": 0,\n    \"false\": 1,\n    \"barely-true\": 2,\n    \"half-true\": 3,\n    \"mostly-true\": 4,\n    \"true\": 5\n}\ndf_train[\"label\"] = df_train[\"label\"].map(label_map)\ndf_valid[\"label\"] = df_valid[\"label\"].map(label_map)\ndf_test[\"label\"] = df_test[\"label\"].map(label_map)\n\n# Преобразуем DataFrame в объекты Dataset\ntrain_dataset = Dataset.from_pandas(df_train)\nvalid_dataset = Dataset.from_pandas(df_valid)\ntest_dataset = Dataset.from_pandas(df_test)\n\n# Загружаем токенизатор\ntokenizer = AutoTokenizer.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\")\n\n# Функция для токенизации\ndef tokenize_function(examples):\n    return tokenizer(\n        examples[\"statement\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=128\n    )\n\n# Применяем токенизацию к датасетам\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\nvalid_dataset = valid_dataset.map(tokenize_function, batched=True)\ntest_dataset = test_dataset.map(tokenize_function, batched=True)\n\n# Удаляем ненужные столбцы\ntrain_dataset = train_dataset.remove_columns([\"statement\"])\nvalid_dataset = valid_dataset.remove_columns([\"statement\"])\ntest_dataset = test_dataset.remove_columns([\"statement\"])\n\n# Загружаем модель\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"huawei-noah/TinyBERT_General_4L_312D\",\n    num_labels=6,\n    ignore_mismatched_sizes=True  # Игнорируем несоответствие размеров\n)\n\n# Настройка параметров обучения\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    eval_strategy=\"epoch\",\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    gradient_accumulation_steps=1,\n    num_train_epochs=5,  # Увеличиваем количество эпох\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    fp16=True,\n    run_name=\"tinybert-finetuning\"  # Уникальное имя эксперимента\n)\n\n# Загружаем метрики\naccuracy_metric = evaluate.load(\"accuracy\")\nf1_metric = evaluate.load(\"f1\")\n\n# Определяем функцию для вычисления метрик\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    \n    # Вычисляем метрики\n    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n    cm = confusion_matrix(labels, predictions, labels=list(range(6)))  # Матрица ошибок\n    \n    return {\n        \"accuracy\": accuracy[\"accuracy\"],\n        \"f1\": f1[\"f1\"],\n        \"confusion_matrix\": cm.tolist()  # Преобразуем матрицу в список\n    }\n\n# Определяем data collator\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# Инициализируем Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\n# Обучение модели\ntrainer.train()\n\n# Оценка модели\ntest_results = trainer.evaluate(test_dataset)\nprint(f\"Test results: {test_results}\")\n\n# --- Добавление вычисления индекса правдоподобия ---\ndef calculate_plausibility_index(probabilities):\n    \"\"\"\n    Вычисляет индекс правдоподобия на основе вероятностей.\n    :param probabilities: Список вероятностей для каждого класса.\n    :return: Индекс правдоподобия.\n    \"\"\"\n    index = np.sum(np.arange(6) * probabilities)\n    return index\n\n# Функция для предсказания и расчета индекса\ndef predict_and_calculate_index(text):\n    \"\"\"\n    Предсказывает метки и вычисляет индекс правдоподобия для входного текста.\n    :param text: Входной текст.\n    :return: Индекс правдоподобия и вероятности.\n    \"\"\"\n    # Токенизация текста\n    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n    # Предсказание\n    with torch.no_grad():\n        outputs = model(**inputs)\n    logits = outputs.logits\n    probabilities = torch.softmax(logits, dim=-1).numpy()[0]\n    # Вычисление индекса\n    index = calculate_plausibility_index(probabilities)\n    return index, probabilities\n\n# Пример использования\nexample_text = \"This is an example statement to test the plausibility index.\"\nindex, probabilities = predict_and_calculate_index(example_text)\nprint(f\"Plausibility Index: {index:.2f}\")\nprint(f\"Probabilities: {probabilities}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:38:15.176638Z","iopub.execute_input":"2025-02-01T07:38:15.176965Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/409 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d0534a803c749b8ba5f71dc918fa0d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"099608f4a1244413ba5f81b0cedfa665"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10240 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c31a3860d5a445df912a73bff3dcf5f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1284 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"524fc336f214414a84d5108a32f779e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1267 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecb6744ef36a42078ee33cdc646fa744"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/62.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5bf8f4e9c1644a9a61a4881d3e1456a"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f05e4c15b9754f4cb9b7e35395f2c238"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d0d65b94640427688c851e27a4fb45a"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    "},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainerCallback\n\n# Класс для сохранения потерь\nclass LossLogger(TrainerCallback):\n    def __init__(self):\n        self.train_losses = []\n        self.val_losses = []\n\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs is not None:\n            if \"loss\" in logs:\n                self.train_losses.append(logs[\"loss\"])  # Потери на обучающей выборке\n            if \"eval_loss\" in logs:\n                self.val_losses.append(logs[\"eval_loss\"])  # Потери на валидационной выборке\n\n# Колбэк\nloss_logger = LossLogger()\n\n# Добавляем колбэк в Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    callbacks=[loss_logger]  # Добавляем колбэк\n)\n\n# Обучение модели\ntrainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Извлекаем потери\ntrain_losses = loss_logger.train_losses\nval_losses = loss_logger.val_losses\n\n# Строим график\nplt.figure(figsize=(10, 6))\nplt.plot(train_losses, label=\"Training Loss\", color=\"blue\")\nplt.plot(val_losses, label=\"Validation Loss\", color=\"orange\")\n\n# Настройки графика\nplt.title(\"Loss Curve\", fontsize=16)\nplt.xlabel(\"Epochs\", fontsize=14)\nplt.ylabel(\"Loss\", fontsize=14)\nplt.legend(fontsize=12)\nplt.grid(True)\n\n# Показываем график\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport numpy as np\n\n# Получаем предсказания модели на тестовой выборке\npredictions = trainer.predict(test_dataset)\npreds = np.argmax(predictions.predictions, axis=-1)  # Предсказанные метки\nlabels = predictions.label_ids  # Истинные метки\n\n# Вычисляем матрицу ошибок\ncm = confusion_matrix(labels, preds, labels=list(range(6)))  # Указываем все классы\nprint(\"Confusion Matrix:\")\nprint(cm)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Создаем тепловую карту\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_map.keys(), yticklabels=label_map.keys())\n\n# Настройки графика\nplt.title(\"Confusion Matrix\", fontsize=16)\nplt.xlabel(\"Predicted Labels\", fontsize=14)\nplt.ylabel(\"True Labels\", fontsize=14)\n\n# Показываем график\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nprint(\"GPU available:\", torch.cuda.is_available())\nprint(\"Device count:\", torch.cuda.device_count())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T18:36:05.126017Z","iopub.execute_input":"2025-01-31T18:36:05.126497Z","iopub.status.idle":"2025-01-31T18:36:08.143252Z","shell.execute_reply.started":"2025-01-31T18:36:05.126461Z","shell.execute_reply":"2025-01-31T18:36:08.142346Z"}},"outputs":[{"name":"stdout","text":"GPU available: True\nDevice count: 1\n","output_type":"stream"}],"execution_count":9}]}